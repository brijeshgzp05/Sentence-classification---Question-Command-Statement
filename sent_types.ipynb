{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sent_types.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAirSkKOQfQW",
        "colab_type": "text"
      },
      "source": [
        "# Sentence classification - Question, Command, Statement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unI1ab5-UTE3",
        "colab_type": "code",
        "outputId": "07e5e5da-c86f-4d4b-b1ec-a48b8f161ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6PBct2EUuwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A93W2-LREYC3",
        "colab_type": "text"
      },
      "source": [
        "## Reading Data and displaying it.\n",
        "I have processed it already. For you raw data is provided in data file1.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbp9nIDPUyCY",
        "colab_type": "code",
        "outputId": "8baaa1a1-2dec-4ab6-b54f-2a18160edc45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "os.chdir(\"/content/gdrive/My Drive\")\n",
        "\n",
        "df = pd.read_csv(\"processed_full_spaadia.csv\")\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and confirm that address for me please</td>\n",
              "      <td>command</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it from birmingham to em london euston please</td>\n",
              "      <td>statement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the th of october</td>\n",
              "      <td>statement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i like to leave on the train</td>\n",
              "      <td>statement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>there the from birmingham new street</td>\n",
              "      <td>statement</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        statement       type\n",
              "0         and confirm that address for me please     command\n",
              "1  it from birmingham to em london euston please   statement\n",
              "2                              the th of october   statement\n",
              "3                   i like to leave on the train   statement\n",
              "4           there the from birmingham new street   statement"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F79yMkBTFCNl",
        "colab_type": "text"
      },
      "source": [
        "## Some more exloration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYrfnHmIg_xy",
        "colab_type": "code",
        "outputId": "a0b8224d-ce89-490c-dbff-4fe85b94084d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210066, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvwUCZiqUxSB",
        "colab_type": "code",
        "outputId": "f1c183b4-a685-456c-df9d-c0eaa9bd193c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "statement    0\n",
            "type         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dchtle3FJeZ",
        "colab_type": "text"
      },
      "source": [
        "## Changing categotical type to labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0fB19v3jeGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "types=df.type.unique()\n",
        "dic={}\n",
        "for i,type_ in enumerate(types):\n",
        "    dic[type_]=i\n",
        "labels=df.type.apply(lambda x:dic[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq_VWDNgFa87",
        "colab_type": "text"
      },
      "source": [
        "## Keras Import "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ifiHQUZjiue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "04a33576-9592-4bec-bb03-983e3e600313"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV-19luUFfVO",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the data through sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzkAoA-mjkrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.statement, df.type, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE0bQn0BjvEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = pd.concat([X_test,y_test],axis=1)\n",
        "train_data = pd.concat([X_train,y_train],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF6aEktJkACB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts=df.statement\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKInGFFbGUn3",
        "colab_type": "text"
      },
      "source": [
        "## Building Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4bAURqLlwhm",
        "colab_type": "code",
        "outputId": "9449a342-cf93-4f9f-8e38-fa1784384f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NUM_WORDS=10**5\n",
        "tokenizer = Tokenizer(num_words=NUM_WORDS,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'',lower=True)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences_train = tokenizer.texts_to_sequences(train_data.statement)\n",
        "sequences_valid=tokenizer.texts_to_sequences(val_data.statement)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 81548 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kocw9dxJGdCF",
        "colab_type": "text"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbqrNjy6mAZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGgEIReWvQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length=50\n",
        "trunc_type='post'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t1Z_J_nWwZl",
        "colab_type": "code",
        "outputId": "1f4d1b6d-2ac1-4a84-b8d1-5b014df8edc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train = pad_sequences(sequences_train,maxlen=max_length, truncating = trunc_type)\n",
        "X_val = pad_sequences(sequences_valid,maxlen=max_length, truncating = trunc_type)\n",
        "y_train = to_categorical(np.asarray(labels[train_data.index]))\n",
        "y_val = to_categorical(np.asarray(labels[val_data.index]))\n",
        "print('Shape of X train and X validation tensor:', X_train.shape,X_val.shape)\n",
        "print('Shape of label train and validation tensor:', y_train.shape,y_val.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X train and X validation tensor: (147046, 50) (63020, 50)\n",
            "Shape of label train and validation tensor: (147046, 3) (63020, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUYMNxNPGrUN",
        "colab_type": "text"
      },
      "source": [
        "## Constructing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvbCIs8kXe60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRj-Y3gNWz02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b2fbed28-0ab9-4769-98ee-42490ee39513"
      },
      "source": [
        "EMBEDDING_DIM=300\n",
        "vocabulary_size=min(len(word_index)+1,NUM_WORDS)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(vocabulary_size,EMBEDDING_DIM,input_length=max_length),\n",
        "    keras.layers.LSTM(16, activation='relu',return_sequences=True),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.LSTM(8, activation='relu'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1veueCDIEaa",
        "colab_type": "text"
      },
      "source": [
        "## Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uWtXYX_Xq2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6d1279e6-03a3-4c5c-e25b-7f34763acef3"
      },
      "source": [
        "adam = Adam(lr=1e-3)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCwdh8DCIz3C",
        "colab_type": "text"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dUDqTiUqLPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jBuXjQWXvXE",
        "colab_type": "code",
        "outputId": "b679a7c4-6ee1-4850-dc61-c5e0cbd2a3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 300)           24464700  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50, 16)            20288     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 16)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 8)                 800       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 24,486,175\n",
            "Trainable params: 24,486,175\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1VA6Vj1I5hK",
        "colab_type": "text"
      },
      "source": [
        "## Creating a callback function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p36tMVbBskCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    if (logs.get('acc')>logs.get('val_acc')):\n",
        "      print(\"\\nOverfitting begins\")\n",
        "      self.model.stop_training=True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz6q3AtdJAcU",
        "colab_type": "text"
      },
      "source": [
        "## Fittng the data to model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul50SNr_X7ZH",
        "colab_type": "code",
        "outputId": "9b31b774-d8f6-444c-d52d-61b25e1c6483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "epochs=10\n",
        "verbose=1\n",
        "batch_size=32\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "history=model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_val, y_val), callbacks=[callbacks])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 147046 samples, validate on 63020 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "147046/147046 [==============================] - 783s 5ms/step - loss: 0.2299 - acc: 0.9199 - val_loss: 0.1371 - val_acc: 0.9532\n",
            "Epoch 2/10\n",
            "147046/147046 [==============================] - 764s 5ms/step - loss: 0.1051 - acc: 0.9633 - val_loss: 0.1098 - val_acc: 0.9623\n",
            "\n",
            "Overfitting begins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F4Fm0j6JPcY",
        "colab_type": "text"
      },
      "source": [
        "## Testing on our own data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd-iQZVIYBZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_comments = [\n",
        "    \"This is a stupid example.\",\n",
        "    \"This is another statement, perhaps this will trick the network\",\n",
        "    \"I don't understand\",\n",
        "    \"What's up?\",\n",
        "    \"open the app\",\n",
        "    \"This is another example\",\n",
        "    \"Do what I tell you\",\n",
        "    \"come over here and listen\",\n",
        "    \"how do you know what to look for\",\n",
        "    \"Remember how good the concert was?\",\n",
        "    \"Who is the greatest basketball player of all time?\",\n",
        "    \"Eat your cereal.\",\n",
        "    \"Usually the prior sentence is not classified properly.\",\n",
        "    \"Don't forget about your homework!\",\n",
        "    \"Can the model identify a sentence without a question mark\",\n",
        "    \"Everything speculated here is VC money and financial bubble with unrelaible financial values. Zomato, uber, paytm, flipkart throw discounts at the rate of losses. May be few can survive at the end. This hurts a lot for SMB too.\",\n",
        "    \"I am trying to keep tabs on electric two-wheeler startup industry in India. Ather energy is emerging as a big name. Anyone knows how they are doing?\",\n",
        "    \"generally a pretty intuitive way to accomplish a task. Want to trash an app Drag it to the trash Want to print a PDF\",\n",
        "    \"Make sure ownership is clear and minimizing opportunities for such problematic outcomes in the second place\",\n",
        "    \"Stop the video and walk away.\"\n",
        "]\n",
        "\n",
        "test_comments_category = [\n",
        "    \"statement\",\n",
        "    \"statement\",\n",
        "    \"statement\",\n",
        "    \"question\",\n",
        "    \"command\",\n",
        "    \"statement\",\n",
        "    \"command\",\n",
        "    \"command\",\n",
        "    \"question\",\n",
        "    \"question\",\n",
        "    \"question\",\n",
        "    \"command\",\n",
        "    \"statement\",\n",
        "    \"command\",\n",
        "    \"question\",\n",
        "    \"statement\",\n",
        "    \"question\",\n",
        "    \"question\",\n",
        "    \"statement\",\n",
        "    \"command\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LApColWZaVzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_single(sent):\n",
        "    l = []\n",
        "    l.append(sent)\n",
        "    sequences_pred = tokenizer.texts_to_sequences(l)\n",
        "    padded_pred = pad_sequences(sequences_pred,maxlen=max_length, truncating = trunc_type)\n",
        "    pred = model.predict([padded_pred])\n",
        "    pred = list(pred[0])\n",
        "    ind = np.argmax(pred)\n",
        "    if ind==0:\n",
        "        return 'command'\n",
        "    elif ind==1:\n",
        "        return 'statement'\n",
        "    else:\n",
        "        return 'question'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvmnmwmYaaPT",
        "colab_type": "code",
        "outputId": "9a1f4c7d-b0c8-4ef4-d537-ddbdcf592c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "for i in range(len(test_comments)):\n",
        "    typ = prediction_single(test_comments[i])\n",
        "    print(test_comments[i],'--------\\nActual : ',test_comments_category[i],'--------prediction : ',typ)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a stupid example. --------\n",
            "Actual :  statement --------prediction :  statement\n",
            "This is another statement, perhaps this will trick the network --------\n",
            "Actual :  statement --------prediction :  statement\n",
            "I don't understand --------\n",
            "Actual :  statement --------prediction :  statement\n",
            "What's up? --------\n",
            "Actual :  question --------prediction :  question\n",
            "open the app --------\n",
            "Actual :  command --------prediction :  statement\n",
            "This is another example --------\n",
            "Actual :  statement --------prediction :  statement\n",
            "Do what I tell you --------\n",
            "Actual :  command --------prediction :  question\n",
            "come over here and listen --------\n",
            "Actual :  command --------prediction :  statement\n",
            "how do you know what to look for --------\n",
            "Actual :  question --------prediction :  question\n",
            "Remember how good the concert was? --------\n",
            "Actual :  question --------prediction :  question\n",
            "Who is the greatest basketball player of all time? --------\n",
            "Actual :  question --------prediction :  question\n",
            "Eat your cereal. --------\n",
            "Actual :  command --------prediction :  statement\n",
            "Usually the prior sentence is not classified properly. --------\n",
            "Actual :  statement --------prediction :  statement\n",
            "Don't forget about your homework! --------\n",
            "Actual :  command --------prediction :  statement\n",
            "Can the model identify a sentence without a question mark --------\n",
            "Actual :  question --------prediction :  statement\n",
            "Everything speculated here is VC money and financial bubble with unrelaible financial values. Zomato, uber, paytm, flipkart throw discounts at the rate of losses. May be few can survive at the end. This hurts a lot for SMB too. --------\n",
            "Actual :  statement --------prediction :  statement\n",
            "I am trying to keep tabs on electric two-wheeler startup industry in India. Ather energy is emerging as a big name. Anyone knows how they are doing? --------\n",
            "Actual :  question --------prediction :  statement\n",
            "generally a pretty intuitive way to accomplish a task. Want to trash an app Drag it to the trash Want to print a PDF --------\n",
            "Actual :  question --------prediction :  statement\n",
            "Make sure ownership is clear and minimizing opportunities for such problematic outcomes in the second place --------\n",
            "Actual :  statement --------prediction :  statement\n",
            "Stop the video and walk away. --------\n",
            "Actual :  command --------prediction :  question\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ejHGM5bafoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"processed_full_spaadia_keras_model_new.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSolXy6t8Q-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('processed_full_spaadia_keras_tokenizer_new.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_zeDicYKTJ5",
        "colab_type": "text"
      },
      "source": [
        "#### As you can see there is an imbalance in data i.e, of command type. But it works good on statements and questions. For commands we need more data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qZAR5xX8dTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}